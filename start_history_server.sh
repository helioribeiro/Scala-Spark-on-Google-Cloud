#!/bin/bash

# Spark History Server Script
# This script starts the Spark History Server to persist UI after jobs finish

echo "ğŸ“Š Starting Spark History Server"
echo "==============================="
echo ""

# Create events directory if it doesn't exist
mkdir -p /tmp/spark-events

echo "ğŸ“ Events directory: /tmp/spark-events"
echo ""

echo "ğŸš€ Starting Spark History Server..."
echo "   This will allow you to access Spark UI after jobs complete"
echo ""

# Start the history server
$SPARK_HOME/sbin/start-history-server.sh

echo ""
echo "âœ… Spark History Server started!"
echo ""
echo "ğŸŒ Access the History Server UI at:"
echo "   ğŸ”— http://localhost:18080"
echo ""
echo "ğŸ“‹ What you can do:"
echo "   â€¢ View completed jobs"
echo "   â€¢ Analyze performance metrics"
echo "   â€¢ Compare different job runs"
echo "   â€¢ Access DAG visualizations"
echo ""
echo "ğŸ’¡ Tips:"
echo "   â€¢ Keep this terminal open to keep the server running"
echo "   â€¢ Run your jobs with event logging enabled (already configured)"
echo "   â€¢ Jobs will appear in the UI after they complete"
echo ""
echo "ğŸ›‘ To stop the server later, run:"
echo "   $SPARK_HOME/sbin/stop-history-server.sh" 